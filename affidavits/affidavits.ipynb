{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Affidavit Archive\n",
      "\n",
      "The [ECI Affidavit Archive](http://affidavitarchive.nic.in/) has archives of candidate affidavits (i.e. declarations) as PDF files of images.\n",
      "\n",
      "This script crawls and downloads these for Parliamentary elections, and also creates a CSV file that has the mapping of file name to constituency details.\n",
      "\n",
      "To run this, install [requests](http://docs.python-requests.org/en/latest/) and [lxml](http://lxml.de/).\n",
      "\n",
      "**Note about the URL format:**\n",
      "\n",
      "http://affidavitarchive.nic.in/DynamicAffidavitDisplay/CANDIDATEAFFIDAVIT.aspx?YEARID=May-2014&AC_No=02&st_code=S05&constType=PC\n",
      "\n",
      "- `constType` must be 'PC'. We're only scraping these for now.\n",
      "- `YEARID` must be 'May-2014'. For past elections, it links back to http://eci.nic.in/eci_main1/LinktoAffidavits.aspx\n",
      "- `st_code` ranges from 'S01' to 'S28' and from 'U01' to 'U07'\n",
      "- `AC_No` is sequential\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import time\n",
      "from urllib import urlopen, urlencode, urlretrieve\n",
      "from lxml.html import parse\n",
      "\n",
      "BASE = 'http://affidavitarchive.nic.in/DynamicAffidavitDisplay/CANDIDATEAFFIDAVIT.aspx'\n",
      "\n",
      "if not os.path.exists('.cache'):\n",
      "    os.makedirs('.cache')\n",
      "    \n",
      "# If file is older than 2 days, download it again\n",
      "OLD = time.time() - 2 * 24 * 60 * 60\n",
      "\n",
      "def candidates(st_code, ac_no):\n",
      "    filename = '{:s}-{:d}'.format(st_code, ac_no)\n",
      "    path = os.path.join('.cache', filename + '.html')\n",
      "    url = BASE + '?' + urlencode({\n",
      "        'YEARID': 'May-2014',\n",
      "        'constType': 'PC',\n",
      "        'st_code': st_code,\n",
      "        'AC_No': ac_no\n",
      "    })\n",
      "    if not os.path.exists(path) or os.stat(path).st_mtime < OLD:\n",
      "        print filename\n",
      "        urlretrieve(url, path)\n",
      "    tree = parse(open(path))\n",
      "    \n",
      "    state = tree.find('.//*[@id=\"ctl00_ContentPlaceHolder1_lblState\"]').text_content()\n",
      "    state = state.replace('STATE NAME: ', '').strip()\n",
      "    pc = tree.find('.//*[@id=\"ctl00_ContentPlaceHolder1_lblConst\"]').text_content()\n",
      "    pc = pc.replace('PC NAME: ', '').strip()\n",
      "    viewstate = tree.find('.//*[@id=\"__VIEWSTATE\"]').get('value')\n",
      "    \n",
      "    # Skip the first 5 <tr>s. They are not relevant\n",
      "    results = []\n",
      "    for row in tree.findall('.//table//tr')[5:]:\n",
      "        cells = row.findall('td')\n",
      "        link = cells[1].find('a').get('href')\n",
      "        results.append({\n",
      "            'URL': url,\n",
      "            'VIEWSTATE': viewstate,\n",
      "            'ST_CODE': st_code,\n",
      "            'PC_CODE': ac_no,\n",
      "            'STATE': state,\n",
      "            'PC': pc,\n",
      "            'NO': cells[0].text_content().strip(),\n",
      "            'NAME': cells[1].text_content().strip(),\n",
      "            'PARTY': cells[2].text_content().strip(),\n",
      "            'LINK': link.split(\"'\")[1],\n",
      "        })\n",
      "    \n",
      "    # If there were no results, remove the file\n",
      "    if not len(results):\n",
      "        os.unlink(path)\n",
      "\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# State codes range from 'S01' to 'S28', and 'U01' to 'U07'. Manually typed from\n",
      "# http://affidavitarchive.nic.in/DynamicAffidavitDisplay/FrmElectionAffidavit.aspx\n",
      "st_codes = [\n",
      "    ('S01', 42),\n",
      "    ('S02', 2),\n",
      "    ('S03', 14),\n",
      "    ('S04', 40),\n",
      "    ('S05', 2),\n",
      "    ('S06', 26),\n",
      "    ('S07', 10),\n",
      "    ('S08', 4),\n",
      "    ('S09', 6),\n",
      "    ('S10', 28),\n",
      "    ('S11', 20),\n",
      "    ('S12', 29),\n",
      "    ('S13', 48),\n",
      "    ('S14', 2),\n",
      "    ('S15', 2),\n",
      "    ('S16', 1),\n",
      "    ('S17', 1),\n",
      "    ('S18', 21),\n",
      "    ('S19', 13),\n",
      "    ('S20', 25),\n",
      "    ('S21', 1),\n",
      "    ('S22', 39),\n",
      "    ('S23', 2),\n",
      "    ('S24', 80),\n",
      "    ('S25', 42),\n",
      "    ('S26', 11),\n",
      "    ('S27', 14),\n",
      "    ('S28', 5),\n",
      "    ('U01', 1),\n",
      "    ('U02', 1),\n",
      "    ('U03', 1),\n",
      "    ('U04', 1),\n",
      "    ('U05', 7),\n",
      "    ('U06', 1),\n",
      "    ('U07', 1),\n",
      "]\n",
      "\n",
      "result = []\n",
      "for st_code, ac_count in st_codes:\n",
      "    for ac_no in range(1, ac_count + 1):\n",
      "        data = list(candidates(st_code, ac_no))\n",
      "        if len(data):\n",
      "            result += data\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "S04-17\n",
        "S09-4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "S24-69"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "S25-10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's save this data in `affidavits.csv`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "with open('affidavits.csv', 'w') as out:\n",
      "    writer = csv.writer(out, lineterminator='\\n')\n",
      "    fields = ['ST_CODE', 'PC_CODE', 'STATE', 'PC', 'NO', 'NAME', 'PARTY']\n",
      "    writer.writerow(fields)\n",
      "    writer.writerows([\n",
      "        [row[field] for field in fields]\n",
      "        for row in result\n",
      "    ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At this point, we have an array, `results`, that has one row per candidate.\n",
      "\n",
      "Now comes the tough part. The links are not HTTP links, but Javascript links. Fortunately, this *can* be scraped, and I have discovered a [\"truly marvellous\"](http://en.wikipedia.org/wiki/Fermat's_Last_Theorem#Fermat.27s_conjecture) technique, which I don't have time to explain thanks to [24 (season 2)](http://en.wikipedia.org/wiki/24_(season_2)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests\n",
      "\n",
      "for row in result:\n",
      "    filename = '{ST_CODE:s}-{PC_CODE:02d}-{NO:s}.zip'.format(**row)\n",
      "    if os.path.exists(filename):\n",
      "        continue\n",
      "\n",
      "    print filename\n",
      "    r = requests.post(row['URL'], data={\n",
      "        '__EVENTTARGET': row['LINK'],\n",
      "        '__EVENTARGUMENT': '',\n",
      "        '_LASTFOCUS': '',\n",
      "        '__VIEWSTATE': row['VIEWSTATE']\n",
      "    })\n",
      "    with open(filename, 'wb') as out:\n",
      "        out.write(r.content)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    }
   ],
   "metadata": {}
  }
 ]
}